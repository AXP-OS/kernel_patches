From 6fdbe50c1b51916b74ec2b05fd193428d157fb12 Mon Sep 17 00:00:00 2001
From: Elliot Berman <quic_eberman@quicinc.com>
Date: Mon, 2 May 2022 12:27:29 -0700
Subject: [PATCH] virt: gunyah: rm_core: Re-use alloc'd message when sending
 requests

No need to allocate a message queue buffer for each message queue
fragment, re-use the same one.

Change-Id: I5743a704ec08732a2e405724ba795d2d8cea90e3
Signed-off-by: Elliot Berman <quic_eberman@quicinc.com>
---
 drivers/virt/gunyah/gh_rm_core.c | 49 +++++++++++++-------------------
 1 file changed, 20 insertions(+), 29 deletions(-)

diff --git a/drivers/virt/gunyah/gh_rm_core.c b/drivers/virt/gunyah/gh_rm_core.c
index ddf17b8ab5634..8d3e7009a4419 100644
--- a/drivers/virt/gunyah/gh_rm_core.c
+++ b/drivers/virt/gunyah/gh_rm_core.c
@@ -567,8 +567,8 @@ static int gh_rm_send_request(u32 message_id,
 	unsigned long tx_flags;
 	u32 num_fragments = 0;
 	size_t payload_size;
-	void *send_buff;
-	int i, ret;
+	void *msg;
+	int i, ret = 0;
 
 	num_fragments = (req_buff_size + GH_RM_MAX_MSG_SIZE_BYTES - 1) /
 			GH_RM_MAX_MSG_SIZE_BYTES;
@@ -585,11 +585,15 @@ static int gh_rm_send_request(u32 message_id,
 		return -E2BIG;
 	}
 
+	msg = kzalloc(GH_RM_MAX_MSG_SIZE_BYTES, GFP_KERNEL);
+	if (!msg)
+		return -ENOMEM;
+
 	if (mutex_lock_interruptible(&gh_rm_send_lock)) {
-		return -ERESTARTSYS;
+		ret = -ERESTARTSYS;
+		goto free_msg;
 	}
 
-	/* Consider also the 'request' packet for the loop count */
 	for (i = 0; i <= num_fragments; i++) {
 		if (buff_size_remaining > GH_RM_MAX_MSG_SIZE_BYTES) {
 			payload_size = GH_RM_MAX_MSG_SIZE_BYTES;
@@ -598,13 +602,10 @@ static int gh_rm_send_request(u32 message_id,
 			payload_size = buff_size_remaining;
 		}
 
-		send_buff = kzalloc(sizeof(*hdr) + payload_size, GFP_KERNEL);
-		if (!send_buff) {
-			mutex_unlock(&gh_rm_send_lock);
-			return -ENOMEM;
-		}
+		memset(msg, 0, GH_RM_MAX_MSG_SIZE_BYTES);
 
-		hdr = send_buff;
+		/* Fill header */
+		hdr = msg;
 		hdr->version = GH_RM_RPC_HDR_VERSION_ONE;
 		hdr->hdr_words = GH_RM_RPC_HDR_WORDS;
 		hdr->type = i == 0 ? GH_RM_RPC_TYPE_REQ : GH_RM_RPC_TYPE_CONT;
@@ -612,12 +613,11 @@ static int gh_rm_send_request(u32 message_id,
 		hdr->seq = connection->seq;
 		hdr->msg_id = message_id;
 
-		memcpy(send_buff + sizeof(*hdr), req_buff_curr, payload_size);
+		/* Copy payload */
+		memcpy(msg + sizeof(*hdr), req_buff_curr, payload_size);
 		req_buff_curr += payload_size;
 
-		/* Force the last fragment (or the request type)
-		 * to be sent immediately to the receiver
-		 */
+		/* Force the last fragment to be sent immediately to the receiver */
 		tx_flags = (i == num_fragments) ? GH_MSGQ_TX_PUSH : 0;
 
 		/* delay sending console characters to RM */
@@ -625,25 +625,16 @@ static int gh_rm_send_request(u32 message_id,
 		    message_id == GH_RM_RPC_MSG_ID_CALL_VM_CONSOLE_FLUSH)
 			udelay(800);
 
-		ret = gh_msgq_send(gh_rm_msgq_desc, send_buff,
-					sizeof(*hdr) + payload_size, tx_flags);
-
-		/*
-		 * In the case of a success, the hypervisor would have consumed
-		 * the buffer. While in the case of a failure, we are going to
-		 * quit anyways. Hence, free the buffer regardless of the
-		 * return value.
-		 */
-		kfree(send_buff);
+		ret = gh_msgq_send(gh_rm_msgq_desc, msg, sizeof(*hdr) + payload_size, tx_flags);
 
-		if (ret) {
-			mutex_unlock(&gh_rm_send_lock);
-			return ret;
-		}
+		if (ret)
+			break;
 	}
 
 	mutex_unlock(&gh_rm_send_lock);
-	return 0;
+free_msg:
+	kfree(msg);
+	return ret;
 }
 
 /**
-- 
GitLab

